{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c3e3f-9c20-46ef-a8fa-b6c289291810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama run brxce/monadgpt modern french\n",
    "#ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24616611-2258-4caf-8d7b-25422512f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liv0232_ideedelaperfectiondelape.txt\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbe1166-0dd6-436c-b904-56e659aaac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alto2txt in ./venv/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.7.1 in ./venv/lib/python3.11/site-packages (from alto2txt) (4.9.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install alto2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5865abc1-ac64-4338-8869-004b39fa5486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIV0144_altos_transcribed  LIV0304_altos_transcribed  venv\n",
      "LIV0227_altos_transcribed  output\n",
      "LIV0299_altos_transcribed  RAG_historical.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "302bb582-2239-4127-9ac7-74e0b5087032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_alto_to_text(input_folder, output_file):\n",
    "    # Define ALTO namespace\n",
    "    ns = {'alto': 'http://www.loc.gov/standards/alto/ns-v4#'}\n",
    "    \n",
    "    # Get all XML files and sort them numerically\n",
    "    xml_files = [f for f in os.listdir(input_folder) if f.endswith('.xml')]\n",
    "    xml_files.sort(key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as txt_file:\n",
    "        for xml_file in xml_files:\n",
    "            xml_path = os.path.join(input_folder, xml_file)\n",
    "            \n",
    "            # Parse the XML\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Find the MainZone TYPE ID\n",
    "            mainzone_id = None\n",
    "            for tag in root.findall(\".//alto:OtherTag\", ns):\n",
    "                if tag.attrib.get('LABEL') == 'MainZone':\n",
    "                    mainzone_id = tag.attrib.get('ID')\n",
    "                    break\n",
    "            \n",
    "            if mainzone_id:\n",
    "                # Find all TextBlocks with the MainZone ID\n",
    "                main_blocks = root.findall(f\".//alto:TextBlock[@TAGREFS='{mainzone_id}']\", ns)\n",
    "                \n",
    "                text_content = []\n",
    "                for block in main_blocks:\n",
    "                    for line in block.findall(\".//alto:TextLine\", ns):\n",
    "                        line_text = []\n",
    "                        for string in line.findall(\".//alto:String\", ns):\n",
    "                            if 'CONTENT' in string.attrib:\n",
    "                                line_text.append(string.attrib['CONTENT'])\n",
    "                        if line_text:\n",
    "                            text_content.append(' '.join(line_text))\n",
    "                \n",
    "                # Write the text with proper line breaks\n",
    "                if text_content:\n",
    "                    txt_file.write('\\n'.join(text_content) + '\\n\\n')\n",
    "            \n",
    "            print(f\"Processed: {xml_file}\")\n",
    "    \n",
    "    print(f\"All text written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d064e062-1df2-455d-87d9-1b0d32009de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: f0-plat-superieur.xml\n",
      "Processed: f1-contreplat-sup.xml\n",
      "Processed: f2-page-de-garde-recto.xml\n",
      "Processed: f3-page-de-garde-verso.xml\n",
      "Processed: f4-np.xml\n",
      "Processed: f5-np.xml\n",
      "Processed: f6-1r.xml\n",
      "Processed: f7-1v.xml\n",
      "Processed: f8-2r.xml\n",
      "Processed: f9-2v.xml\n",
      "Processed: f10-3r.xml\n",
      "Processed: f11-3v.xml\n",
      "Processed: f12-4r.xml\n",
      "Processed: f13-4v.xml\n",
      "Processed: f14-5r.xml\n",
      "Processed: f15-5v.xml\n",
      "Processed: f16-6r.xml\n",
      "Processed: f17-6v.xml\n",
      "Processed: f18-7r.xml\n",
      "Processed: f19-7v.xml\n",
      "Processed: f20-8r.xml\n",
      "Processed: f21-8v.xml\n",
      "Processed: f22-9r.xml\n",
      "Processed: f23-9v.xml\n",
      "Processed: f24-10r.xml\n",
      "Processed: f25-10v.xml\n",
      "Processed: f26-11r.xml\n",
      "Processed: f27-11v.xml\n",
      "Processed: f28-12r.xml\n",
      "Processed: f29-12v.xml\n",
      "Processed: f30-13r.xml\n",
      "Processed: f31-13v.xml\n",
      "Processed: f32-14r.xml\n",
      "Processed: f33-14v.xml\n",
      "Processed: f34-15r.xml\n",
      "Processed: f35-15v.xml\n",
      "Processed: f36-16r.xml\n",
      "Processed: f37-16v.xml\n",
      "Processed: f38-17r.xml\n",
      "Processed: f39-17v.xml\n",
      "Processed: f40-18r.xml\n",
      "Processed: f41-18v.xml\n",
      "Processed: f42-19r.xml\n",
      "Processed: f43-19v.xml\n",
      "Processed: f44-20r.xml\n",
      "Processed: f45-20v.xml\n",
      "Processed: f46-21r.xml\n",
      "Processed: f47-21v.xml\n",
      "Processed: f48-22r.xml\n",
      "Processed: f49-22v.xml\n",
      "Processed: f50-23r.xml\n",
      "Processed: f51-23v.xml\n",
      "Processed: f52-24r.xml\n",
      "Processed: f53-24v.xml\n",
      "Processed: f54-25r.xml\n",
      "Processed: f55-25v.xml\n",
      "Processed: f56-28r.xml\n",
      "Processed: f57-28v.xml\n",
      "Processed: f58-27r.xml\n",
      "Processed: f59-27v.xml\n",
      "Processed: f60-26r.xml\n",
      "Processed: f61-26v.xml\n",
      "Processed: f62-29r.xml\n",
      "Processed: f63-29v.xml\n",
      "Processed: f64-30r.xml\n",
      "Processed: f65-30v.xml\n",
      "Processed: f66-31r.xml\n",
      "Processed: f67-31v.xml\n",
      "Processed: f68-32r.xml\n",
      "Processed: f69-32v.xml\n",
      "Processed: f70-33r.xml\n",
      "Processed: f71-33v.xml\n",
      "Processed: f72-34r.xml\n",
      "Processed: f73-34v.xml\n",
      "Processed: f74-35r.xml\n",
      "Processed: f75-35v.xml\n",
      "Processed: f76-36r.xml\n",
      "Processed: f77-36v.xml\n",
      "Processed: f78-37r.xml\n",
      "Processed: f79-37v.xml\n",
      "Processed: f80-38r.xml\n",
      "Processed: f81-38v.xml\n",
      "Processed: f82-39r.xml\n",
      "Processed: f83-39v.xml\n",
      "Processed: f84-40r.xml\n",
      "Processed: f85-40v.xml\n",
      "Processed: f86-page-de-garde-recto.xml\n",
      "Processed: f87-page-de-garde-verso.xml\n",
      "Processed: f88-contreplat-inf.xml\n",
      "Processed: f89-plat-inferieur.xml\n",
      "All text written to LIV0227_altos_transcribed.txt\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_folder = 'LIV0227_altos_transcribed'\n",
    "output_folder = 'LIV0227_altos_transcribed.txt'\n",
    "convert_alto_to_text(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7fb31b-d94b-4253-8c95-21aaadde9534",
   "metadata": {},
   "source": [
    "# Normalisation\n",
    "`!git clone https://github.com/rbawden/ModFr-Norm.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86952f9-78f4-45a3-8b54-5f0e84caf796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:17\u001b[0mm\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0mm\n",
      "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m933.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m944.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached aiohttp-3.11.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m899.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m904.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m921.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Using cached propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached yarl-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, tzdata, tqdm, sympy, safetensors, regex, pyarrow, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, fsspec, frozenlist, filelock, dill, aiohappyeyeballs, yarl, triton, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, aiosignal, tokenizers, nvidia-cusolver-cu12, aiohttp, transformers, torch, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aiosignal-1.3.1 datasets-3.1.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 propcache-0.2.0 pyarrow-18.0.0 pytz-2024.2 regex-2024.11.6 safetensors-0.4.5 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 tqdm-4.67.1 transformers-4.46.3 triton-3.1.0 tzdata-2024.2 xxhash-3.5.0 yarl-1.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d15819-ddcd-4ad6-bb27-f7e287766af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def regroup_lines_into_sentences(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            sentences = []\n",
    "            current_sentence = \"\"\n",
    "\n",
    "            for line in lines:\n",
    "                line = line.strip()  # Supprimer les espaces en début et fin de ligne\n",
    "                if line:  # Vérifier si la ligne n'est pas vide\n",
    "                    # Ajouter la ligne à la phrase courante\n",
    "                    current_sentence += line + \" \"\n",
    "                    if re.search(r'[.!?]$', line):  # Vérifier si la ligne se termine par un marqueur de fin de phrase\n",
    "                        sentences.append(current_sentence.strip())  # Ajouter la phrase complète à la liste\n",
    "                        current_sentence = \"\"  # Réinitialiser la phrase courante\n",
    "                    current_sentence = current_sentence.replace('¬ ', '')  # Remplacer '¬ ' par rien\n",
    "            return sentences\n",
    "    except FileNotFoundError:\n",
    "        return \"Fichier non trouvé.\"\n",
    "\n",
    "file_path = output_folder  # Remplacez ceci par le chemin de votre fichier .txt\n",
    "sentences = regroup_lines_into_sentences(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503f0c51-6578-466d-b8d4-ce09d01fef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d964ca9f-1817-49cf-b26f-48b005ff278a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at rbawden/modern_french_normalisation and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c780bf10b948d988f65ab69fa97585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing text:   0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line: VRCE que le Sieur lean Couſin voulant faire les demonſtrations neceſY ſaires à l’inſtruction & parfaite intelligence de l’Art de Portraicture, il a eſté obligé de parler des lignes les plus ordinaires de la Geometrie, qui ſont la Perpendiculaire, Diagonale, Parallele, Orthogonale, & autres; & de leurs interſections.\n",
      "Error details: list index out of range\n",
      "Error processing line: A ....EIAISPABA.PAVY& .M ..22 Q ..- - . . so. e..\n",
      "Error details: list index out of range\n",
      "Error processing line: JOVR racourcir les mains, faut tirer lignes perpendiculaires punctuées des Y mains veuës de coſté ou profil, ma rquées de leurs proportions & meſures 1.2.3.\n",
      "Error details: list index out of range\n",
      "Error processing line: A u A B a Ain IN 2 vupe eu Palim e 2 2 18 2L F Lii 14 – PARTICVLARITEZ DV CORPS HVMAIN, TANT QV HEVANTQVE UV DERRIERE, DENET LES ESPAVEEA iuſques aux genitoires, & proportion d’iceluy.\n",
      "Error details: list index out of range\n",
      "Error processing line: I u un vn me 5 Hesſgcccras:„, m tum 2 lunt..\n",
      "Error details: list index out of range\n",
      "Error processing line: . 24 - - » 2 .. . - - . !.. .....\n",
      "Error details: list index out of range\n",
      "Error processing line: & declarer comme on les appelle communément. La ligne perpendiculaire ou à plomb eſt marquée A. La ligne au niueau ou niuellée B. La ligne penchante tant d’vn coſté que d’autre, autrement diagonale, que les Menuiſiers appellent ligne à anglet, eſt marquée C. La ligne punctuée D. La ligne courbe, qui ſe fait auec le compas E. Et la ligne parallele eſt marquée F. Par le moyen deſquelles lignes s’engendrent les interſections ſuiuantes: ſçauoir l’interſection de la ligne perpendiculaire, & de la ligne à niueau, qu’on dit orthogonale, & que les Maſſons appellent le trait quarré, & eſt marquée G. L’interſection des lignes courbes marquée H.\n",
      "Error details: list index out of range\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "normaliser = pipeline(model=\"rbawden/modern_french_normalisation\", batch_size=32, beam_size=5, cache_file=\"./cache.pickle\", device=0, trust_remote_code=True)\n",
    "\n",
    "\n",
    "with open(\"normalized.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    # Wrap sentences with tqdm and store total length\n",
    "    for line in tqdm(sentences, desc=\"Normalizing text\"):\n",
    "        try:\n",
    "            normalized_line = normaliser([line])\n",
    "            output_file.write(normalized_line[0]['text'].strip() + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {line}\")\n",
    "            print(f\"Error details: {e}\")\n",
    "            output_file.write(line.strip() + \"\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f8bd9-42a8-4280-a50b-6e5fce81f6a7",
   "metadata": {},
   "source": [
    "# Analyse document\n",
    "https://github.com/langchain-ai/langchain/blob/master/cookbook/analyze_document.ipynb\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08403c0b-788d-4ef0-89df-2224f8f21278",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce10598-6273-45a0-afaa-61d013bfd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/normalized.txt\") as f:\n",
    "    state_of_the_union = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef878a84-1e87-448e-a71e-5016da49e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mixtral:8x7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b44479e9-6310-40e9-bfdb-84a04af5b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3880d85c-bd42-4964-b011-a0d02f3af18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bcd8de3-c0ae-4d16-8055-6bcfa173bca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The author does not express a specific opinion about estampes in general, but they do mention that some prints or academic studies must be adjusted according to perspective and the original viewpoint. They also praise a particular engraving for its merit, grandeur, rare considerations, and admirable expression. Additionally, they criticize another engraving for lacking force in expressing violent passions. However, these comments are specific to individual works rather than estampes as a whole. Therefore, it is not possible to determine the author's overall opinion about estampes based on this document alone.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=state_of_the_union,\n",
    "    question=\"What does the author think about estampes?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e1ba570-6d35-4bac-b5a7-d48ba1e13381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The document is a book written by Roland Freart Sieur de Chambray titled \"IDE DE DE PERFECTION DE LA PEINTURE\" and published in Le Mans by IA CQVESYs AMBART. The book aims to demonstrate the principles of art and painting through examples, comparing ancient painters like Leonardo da Vinci, Raphael, Julius Roman, and Poussin with some modern French painters. The author emphasizes the importance of perspective in painting and provides axioms for it. The document also highlights the significance of accurately depicting Costumes to enhance the quality of a painter\\'s work and avoid criticism.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=state_of_the_union,\n",
    "    question=\"Summarizes the document and the author's thinking\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8523302d-962a-41f6-923f-32ed8a1c40ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The president did not mention Michael Jackson.\\n\\nThe individuals cited by the author in these arguments are:\\n\\n1. Géomettres (geometers)\\n2. Peintres (painters)\\n3. Es (artists or people who make engravings)\\n4. Madame (a person to whom the document is addressed)\\n5. Raphael\\n6. Marc-Antoine\\n7. The women in the engraving\\n8. The bourreaux (executioners) in the engraving\\n9. The assassins of \"ces urs petits In-ô\"\\n10. The malheureuses mères (unhappy mothers) of the children being killed\\n11. The Peintre (the Painter), who is Raphael.\\n12. NÔTRE SEIGNEUR (Jesus Christ)\\n13. La Vierge (Virgin Mary)\\n14. Les Maries (the Marys, plural form of Marie in French, likely referring to Mary Magdalene and other female followers of Jesus)\\n15. Joseph JRimathie (Joseph of Arimathea)\\n16. Nicodeme (Nicodemus)\\n17. Saint Jean (John the Apostle)\\n18. Ioseph d\\'Arimathie (Joseph of Arimathea, mentioned again)\\n19. La PEINTVRE (the Painter, generic term, not an individual)\\n20. The author himself\\n21. Tout le reste (generic term, not an individual)\\n22. The author\\'s nation\\'s painters\\n23. The Peintres de ç de h\\n24. The Italians\\n25. Albert Durer, who is referred to as the \"plus grand Maître des Tramontains\"\\n\\nNote: The author mentions some terms like \"les passions\", \"la dévotion\", and \"l\\'amour\" but these are not individuals.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_document_chain.run(\n",
    "    input_document=state_of_the_union,\n",
    "    question=\"Give me a list of all the individuals cited by the author in these arguments\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9d5ec-a6c1-4046-a9da-5a788b73a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation -> https://python.langchain.com/docs/use_cases/question_answering/citations/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcf605-9070-4f40-8f45-c5922e97991a",
   "metadata": {},
   "source": [
    "# RAG \n",
    "https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bcb59b-4a62-4ea4-bc6a-7e2645ddb3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
